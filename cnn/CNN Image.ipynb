{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4e98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from sgan.data.loader import data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6638b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, obs_len=12, pred_len=8, delim=\"tab\", skip=1, metric=\"meter\", batch_size=16, loader_num_workers=1):\n",
    "        self.obs_len = obs_len\n",
    "        self.pred_len = pred_len\n",
    "        self.delim = delim\n",
    "        self.skip = skip\n",
    "        self.metric = metric\n",
    "        self.batch_size = batch_size\n",
    "        self.loader_num_workers = loader_num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b86cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/mnt/c/Users/ktwzj/code/data/nba/nba-cross.s025/train_sample\"\n",
    "args = Config()\n",
    "train_dset, train_loader = data_loader(args, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    obs_traj = batch[0]\n",
    "    print(obs_traj.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_width = 28.7\n",
    "field_height = 15.2\n",
    "scene = obs_traj[:, :11, :]\n",
    "sampling_scale_factor = 50\n",
    "sampling_resolution = (int(sampling_scale_factor * field_width), int(sampling_scale_factor * field_height) )\n",
    "image_grid = np.zeros((11, sampling_resolution[1], sampling_resolution[0]))\n",
    "image = np.zeros((sampling_resolution[1], sampling_resolution[0]), np.uint8)\n",
    "def build_map_function(scale_factor):\n",
    "    def f (x, y):\n",
    "        return x * scale_factor, y * scale_factor\n",
    "    return f\n",
    "sampling_map_func = build_map_function(sampling_scale_factor)\n",
    "# image = cv2.fromarray(image)\n",
    "image\n",
    "center_coordinates = (129, 30)\n",
    " \n",
    "# Radius of circle\n",
    "radius = 3\n",
    "  \n",
    "# Blue color in BGR\n",
    "color = 128\n",
    "  \n",
    "# Line thickness of 2 px\n",
    "thickness = -1\n",
    "  \n",
    "# Using cv2.circle() method\n",
    "# Draw a circle with blue line borders of thickness of 2 px\n",
    "agent = scene[:, 0, :]\n",
    "for i in range(agent.shape[0]):\n",
    "    x = agent[i,0].item()\n",
    "    y = agent[i, 1].item()\n",
    "#     print(x.item())\n",
    "    x,y = sampling_map_func(x,y)\n",
    "    center_coordinates = (int(x), int(y))\n",
    "    image = cv2.circle(image, center_coordinates, radius, color, thickness)\n",
    "blur = cv2.GaussianBlur(image,(5,5),0)\n",
    "blur = cv2.GaussianBlur(blur,(5,5),0)\n",
    "blur = cv2.GaussianBlur(blur,(5,5),0)\n",
    "\n",
    "blur = cv2.GaussianBlur(blur,(5,5),0)\n",
    "blur = cv2.GaussianBlur(blur,(5,5),0)\n",
    "blur = cv2.GaussianBlur(blur,(5,5),0)\n",
    "blur = cv2.GaussianBlur(blur,(5,5),0)\n",
    "blur = cv2.GaussianBlur(blur,(5,5),0)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "dilation = cv2.dilate(blur,kernel,iterations = 5)\n",
    "\n",
    "plt.imshow(blur, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(131),plt.imshow(image,cmap=\"gray\"),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132),plt.imshow(blur, cmap=\"gray\"),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133),plt.imshow(dilation, cmap=\"gray\"),plt.title('Dilation')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "# plt.show()\n",
    "dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c3653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrajectoryDrawer:\n",
    "    def __init__(self, sampling_scale_factor=50, target_size=[572, 572],drawing_mode=\"blur\"):\n",
    "        self.sampling_scale_factor = sampling_scale_factor\n",
    "        self.drawing_mode=drawing_mode\n",
    "        self.target_size = target_size\n",
    "        self.agent_num = 11\n",
    "    def transform_sampling_coords (self, x, y):\n",
    "        return x * self.sampling_scale_factor, y * self.sampling_scale_factor\n",
    "    \n",
    "    def generate_trajectory_image(self, agent, image):\n",
    "        for i in range(agent.size(0)):\n",
    "            x = agent[i,0].item()\n",
    "            y = agent[i, 1].item()\n",
    "            x,y = self.transform_sampling_coords(x,y)\n",
    "            center_coordinates = (int(x), int(y))\n",
    "            radius = 3\n",
    "            color = 128\n",
    "            thickness = -1\n",
    "            image = cv2.circle(image, center_coordinates, radius, color, thickness)\n",
    "\n",
    "            image = cv2.GaussianBlur(image,(5,5),0)\n",
    "            image = cv2.GaussianBlur(image,(5,5),0)\n",
    "            image = cv2.GaussianBlur(image,(5,5),0)\n",
    "            image = cv2.GaussianBlur(image,(5,5),0)\n",
    "            image = cv2.GaussianBlur(image,(5,5),0)\n",
    "            image = cv2.GaussianBlur(image,(5,5),0)\n",
    "            kernel = np.ones((3,3),np.uint8)\n",
    "            resized = cv2.resize(image,self.target_size, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        return resized\n",
    "\n",
    "    def generate_scene_image(self, scene):  \n",
    "        channels = []\n",
    "        for i in range(scene.size(1)):\n",
    "            agent_image = np.zeros((sampling_resolution[1], sampling_resolution[0]), np.uint8)\n",
    "            agent = scene[:, i, :]\n",
    "            channel = self.generate_trajectory_image(agent, agent_image)\n",
    "            channel = np.array(channel)\n",
    "            channels.append(channel)\n",
    "        scene_image = np.stack(channels, axis=2)\n",
    "        return scene_image\n",
    "    \n",
    "    def generate_batch_images(self, traj_batch):\n",
    "        batch_size = traj_batch.size(1) // self.agent_num\n",
    "        batch_images = []\n",
    "        for i in range(batch_size):\n",
    "            scene = traj_batch[:, i*self.agent_num: (i+1) * self.agent_num, :]\n",
    "            scene_image = self.generate_scene_image(scene)\n",
    "            batch_images.append(scene_image)\n",
    "        batch_images = np.stack(batch_images)\n",
    "        batch_images = torch.Tensor(batch_images)\n",
    "        batch_images = batch_images.permute(0, 3, 1, 2)\n",
    "        return batch_images\n",
    "drawer = TrajectoryDrawer()\n",
    "image = drawer.generate_batch_images(obs_traj)\n",
    "image.size()\n",
    "# image.shape\n",
    "# plt.imshow(image[:,:,:1], cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9344e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class LNet(nn.Module):\n",
    "    def __init__(self, n_channels, bilinear=True):\n",
    "        super(LNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        return x5\n",
    " \n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer = TrajectoryDrawer()\n",
    "image = drawer.generate_batch_images(obs_traj)\n",
    "model = LNet(n_channels=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.empty_cache()\n",
    "r = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab10b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
